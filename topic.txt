Capacity Provisioning: 

Choosing the right EC2 instance size is crucial for effective capacity provisioning in AWS Elastic Beanstalk. Here are some key points:

Start Small

Begin with t2.micro instances for minimal initial traffic.

Scale up to larger instances like m5.large as demands grow.

Match Instance Type to Workload

Use compute-optimized (C5, C6) for compute-heavy apps.

Use memory-optimized (R4, R5, X1) for data-intensive, in-memory apps.

Use storage-optimized (I3, D2) for apps with large storage I/O.

Leverage Auto Scaling

Configure auto-scaling based on metrics like CPU utilisation or network traffic.

Automatically provision capacity to match demand without manual effort.

Example

For startups, start with cost-effective t2.micro, and auto-scale to m5.large as user base and processing needs grow. This supports growth without downtime while only paying for needed capacity.

By selecting the right instance types and using Elastic Beanstalk auto-scaling, you can optimise capacity provisioning, maintain performance, and control costs as your application scales.

Auto-Scaling: 

Elastic Beanstalk provides various auto-scaling policies to dynamically adjust EC2 instance count based on specific metrics, catering to diverse application needs for optimal performance and cost-effectiveness.

Auto-Scaling Based on Metrics:

Elastic Beanstalk allows defining auto-scaling policies to automatically adjust EC2 instance count based on metrics, ensuring sufficient resources during traffic spikes and cost optimisation during low demand.

Scale Out

Configure scale-out policy with metric (e.g., CPU utilisation), threshold (e.g., 80%), and action (e.g., add 1 instance).

Elastic Beanstalk monitors the metric and launches instances when the threshold is exceeded.

Other metrics like network traffic, disk I/O, or custom metrics can also trigger scale-out.

Scale In

Define scale-in policy with metric (e.g., network traffic), threshold (e.g., 2 MB/second), and action (e.g., remove 1 instance).

Elastic Beanstalk terminates instances when the metric drops below the threshold.

Adjust thresholds, metrics, and actions based on your application's needs.

Memory-Based Scaling:

Automatically adjust capacity based on memory utilisation, suitable for memory-intensive applications.

Configure auto-scaling policy based on memory utilisation, ideal for memory-intensive applications.

Example: Set a policy to add instances when average memory utilisation exceeds a threshold.

Disk I/O-Based Scaling:

Scale instances based on disk read/write operations or disk queue length metrics, beneficial for applications with heavy disk I/O requirements.

Support for scaling based on disk read/write operations or disk queue length metrics, beneficial for applications with heavy disk I/O requirements.

Application-Specific Metrics:

Customise auto-scaling based on application-level metrics like active user sessions or queue lengths.

Define custom metrics published by your application to trigger auto-scaling events, allowing scaling based on application-level indicators such as active user sessions or queue lengths.

Target Tracking Scaling:

Automatically adjust capacity to maintain specific metric values, ensuring efficient resource utilisation.

Utilise target tracking scaling policies to automatically adjust capacity to maintain specific metric values, ensuring efficient resource utilisation.

Example: Maintain CPU utilisation around 50%.

Scheduled Scaling:

Define recurring schedules for increasing or decreasing capacity based on anticipated traffic patterns.

Employ scheduled scaling to define recurring schedules for increasing or decreasing capacity based on anticipated traffic patterns.
